<<<<<<< HEAD
{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"0vmDOXcru6CH"},"source":["# 1 - Seq2Seq with Neural Networks for Household Load Data"]},{"cell_type":"markdown","metadata":{"id":"anXQdBx1u6CL"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6109,"status":"ok","timestamp":1670944368236,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"9WoPuZYZu6CM"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os, sys\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","import torch.optim as optim\n","import pytorch_lightning as pl\n","from pytorch_lightning import LightningModule\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, Callback\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from pytorch_lightning.loggers import WandbLogger\n","from PIL import Image\n","from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n","from io import BytesIO\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","#import plotly.express as px\n","\n","from scipy.stats import boxcox\n","\n","\n","import wandb\n","wandb.login()\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class LRMonitor(Callback):\n","    def __init__(self, monitor='val_loss', mode='min', factor=0.5, patience=3, min_lr=1e-6, verbose=False):\n","        super().__init__()\n","        self.monitor = monitor\n","        self.mode = mode\n","        self.factor = factor\n","        self.patience = patience\n","        self.min_lr = min_lr\n","        self.verbose = verbose\n","\n","        self.scheduler = None\n","        self.best_score = None\n","        self.num_bad_epochs = None\n","\n","    def on_train_start(self, trainer, pl_module):\n","        optimizer = trainer.optimizers[0]\n","        self.scheduler = ReduceLROnPlateau(optimizer, mode=self.mode, factor=self.factor, patience=self.patience, min_lr=self.min_lr, verbose=self.verbose)\n","\n","    def on_validation_end(self, trainer, pl_module):\n","        logs = trainer.callback_metrics\n","        current_score = logs[self.monitor]\n","        if self.best_score is None:\n","            self.best_score = current_score\n","            self.num_bad_epochs = 0\n","        elif self._compare_score(current_score, self.best_score):\n","            self.best_score = current_score\n","            self.num_bad_epochs = 0\n","        else:\n","            self.num_bad_epochs += 1\n","            if self.num_bad_epochs >= self.patience:\n","                if self.verbose:\n","                    print(f'Reducing learning rate. Best score: {self.best_score}, Current score: {current_score}')\n","                self.scheduler.step(self.best_score)\n","                self.best_score = None\n","                self.num_bad_epochs = 0\n","\n","    def _compare_score(self, current_score, best_score):\n","        if self.mode == 'min':\n","            return current_score < best_score\n","        else:\n","            return current_score > best_score\n","\n","\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["class ElectricalLoadDataset(Dataset):\n","    def __init__(self, data_dir, \n","                input_chunk_size,\n","                output_chunk_size, \n","                scaler = None,\n","                timeenc=0,\n","                split='train', \n","                train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, SFH = -1):\n","        \n","        \n","        self.input_chunk_size = input_chunk_size\n","        self.output_chunk_size = output_chunk_size\n","        self.scaler = scaler\n","        self.timeenc = timeenc\n","        self.SFH = SFH\n","\n","        load_series = self._load_data(data_dir)\n","\n","        if self.scaler is None and split == 'train':\n","            self.scaler = MinMaxScaler()\n","            self.scaler.fit(load_series[:int(train_ratio * len(load_series))])\n","\n","        if split == 'train':\n","            self.load_series = self.scaler.transform(load_series[:int(train_ratio * len(load_series))])\n","        elif split == 'val':\n","            self.load_series = self.scaler.transform(load_series[int(train_ratio * len(load_series)):int((train_ratio + val_ratio) * len(load_series))])\n","        elif split == 'test':\n","            self.load_series = self.scaler.transform(load_series[int((train_ratio + val_ratio) * len(load_series)):])\n","\n","\n","    def __len__(self):\n","        return len(self.load_series) - self.input_chunk_size - self.output_chunk_size\n","\n","    def __getitem__(self, idx):\n","        input_chunk = self.load_series[idx:idx+self.input_chunk_size]\n","        output_chunk = self.load_series[idx+self.input_chunk_size-1:idx+self.input_chunk_size+self.output_chunk_size-1]\n","\n","        return input_chunk, output_chunk\n","\n","    def _load_data(self, data_dir):\n","        df = pd.read_csv(os.path.join(data_dir, 'load_data_15min_watts.csv'), index_col=0, parse_dates=True)[:int(1e4)]\n","        df = df.iloc[:, [self.SFH]]\n","        if self.timeenc == 1:\n","            df = self.timeenc_1(df)\n","        elif self.timeenc == 2:\n","            df = self.timeenc_2(df)\n","        else:\n","            pass\n","\n","        return df.values\n","            \n","    def timeenc_1(self, df):\n","        # minute of the day\n","        df['minute'] = df.index.hour * 60 + df.index.minute\n","        # day of the week\n","        df['dayofweek'] = df.index.dayofweek\n","        return df\n","\n","\n","class ElectricalLoadDataLoader(DataLoader):\n","    def __init__(self, *args, **kwargs):\n","        super(ElectricalLoadDataLoader, self).__init__(*args, **kwargs)\n","        self.collate_fn = self.collate_fn_\n","\n","    def collate_fn_(self, batch):\n","        input_chunks, output_chunks = zip(*batch)\n","        input_tensor = torch.FloatTensor(input_chunks)\n","        output_tensor = torch.FloatTensor(output_chunks)\n","        return input_tensor, output_tensor\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## The classic Seq2Seq model with a GRU encoder and decoder \n","\n","(Sutskever et al. 2014)\n","https://arxiv.org/abs/1409.3215"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["class Encoder(LightningModule):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        \n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n","        out, hidden = self.gru(x, h0)\n","        return out, hidden\n","    \n","\n","class Decoder(LightningModule):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, input_size)\n","\n","\n","    def forward(self, x, hidden):\n","        out, hidden = self.gru(x, hidden)\n","        out = self.fc(out)\n","        return out, hidden\n"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["class Seq2Seq(LightningModule):\n","    \n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.3):\n","        N, _, _ = src.shape\n","        N, output_chunk_size , output_size = trg.shape\n","        outputs = torch.zeros(N, output_chunk_size, output_size).to(self.device)\n","        out, hidden = self.encoder(src)\n","        inp = src[:,-1,:].unsqueeze(1)\n","        \n","        for t in range(0, output_chunk_size):\n","            output, hidden = self.decoder(inp, hidden)\n","            outputs[:,t,:] = output.squeeze(1)\n","            teacher_force = np.random.random() < teacher_forcing_ratio\n","            if teacher_force and self.training:\n","                inp = trg[:,t,:].unsqueeze(1)\n","            else:\n","                inp = output\n","        return outputs\n","\n","    def training_step(self, batch):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('train_loss', loss)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('val_loss', loss)\n","        if batch_idx == 0:\n","            buffers = self._plot_predictions(output, trg)\n","            # Combine the image buffers into a single image\n","            images = [np.array(Image.open(buffer)) for buffer in buffers]\n","            combined_image = np.concatenate(images, axis=0)\n","            # Log the combined image to WandB\n","            wandb.log({\"predictions_val_dataset\": wandb.Image(combined_image)})\n","        return loss\n","    \n","    def test_step(self, batch, batch_idx):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('test_loss', loss)\n","        if batch_idx == 0:\n","            buffers = self._plot_predictions(output, trg)\n","            # Combine the image buffers into a single image\n","            images = [np.array(Image.open(buffer)) for buffer in buffers]\n","            combined_image = np.concatenate(images, axis=0)\n","            # Log the combined image to WandB\n","            wandb.log({\"predictions_test_dataset\": wandb.Image(combined_image)})\n","        return loss\n","        \n","    def _plot_predictions(self, preds, actuals):\n","        preds = preds.detach().cpu().numpy()\n","        actuals = actuals.detach().cpu().numpy()\n","        buffers = []\n","        for i in range(preds.shape[0]):\n","            fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n","            # plotting the i-th sequence in the batch\n","            ax.plot(preds[i, :, 0], label='Predictions')\n","            ax.plot(actuals[i, :, 0], label='Actuals')\n","            ax.legend()\n","            # Convert the figure to an imge buffer\n","            canvas = FigureCanvas(fig)\n","            buffer = BytesIO()\n","            canvas.print_figure(buffer, format='png')\n","            buffer.seek(0)\n","            # Close the figure to save memory\n","            plt.close(fig)\n","            # Append the image buffer to the list of buffers\n","            buffers.append(buffer)\n","        # Return the list of image buffers\n","        return buffers\n","\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=1e-3)\n","    "]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["\n","BATCH_SIZE = 16\n","N_LAGS = 96\n","N_STEPS = 96\n","HIDDEN_SIZE = 128\n","\n","train = ElectricalLoadDataset(data_dir='../data', input_chunk_size=N_LAGS, output_chunk_size=N_STEPS, split='train', train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, timeenc=0)\n","train_loader = ElectricalLoadDataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n","val = ElectricalLoadDataset(data_dir='../data', scaler = train.scaler, input_chunk_size=N_LAGS, output_chunk_size=N_STEPS, split='val', train_ratio=0.8, val_ratio=0.1, test_ratio=0.1,  timeenc=0)\n","val_loader = ElectricalLoadDataLoader(val, batch_size=BATCH_SIZE, shuffle=False)\n","test = ElectricalLoadDataset(data_dir='../data', scaler = train.scaler, input_chunk_size=N_LAGS, output_chunk_size=N_STEPS, split='test', train_ratio=0.8, val_ratio=0.1, test_ratio=0.1,  timeenc=0)\n","test_loader = ElectricalLoadDataLoader(test, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 96, 1]) torch.Size([16, 96, 1])\n"]},{"data":{"text/plain":["<matplotlib.legend.Legend at 0x1a3d6f14e20>"]},"execution_count":58,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 2000x1000 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Checking the shape of the data\n","for i , (input_chunk, output_chunk) in enumerate(val_loader):\n","    print(input_chunk.shape, output_chunk.shape)\n","    break\n","# Plotting one sampple from the dataset\n","# arrange so the input chunk is on the left and the output chunk is on the right\n","\n","plt.figure(figsize=(20, 10))\n","plt.plot(np.arange(96), input_chunk[0].numpy(), label='input')\n","plt.plot(np.arange(95, 191), output_chunk[0].numpy(), label='output')\n","plt.legend()\n","\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de149386a5024516b5b4bcef6d7ecd64","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.14.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\LoadLanguageModel\\bin\\wandb\\run-20230403_110245-v5fxjond</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/wattcast/SFH%20Load%20Forecasting/runs/v5fxjond' target=\"_blank\">avid-feather-16</a></strong> to <a href='https://wandb.ai/wattcast/SFH%20Load%20Forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/wattcast/SFH%20Load%20Forecasting' target=\"_blank\">https://wandb.ai/wattcast/SFH%20Load%20Forecasting</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/wattcast/SFH%20Load%20Forecasting/runs/v5fxjond' target=\"_blank\">https://wandb.ai/wattcast/SFH%20Load%20Forecasting/runs/v5fxjond</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name    | Type    | Params\n","------------------------------------\n","0 | encoder | Encoder | 50.3 K\n","1 | decoder | Decoder | 50.4 K\n","------------------------------------\n","100 K     Trainable params\n","0         Non-trainable params\n","100 K     Total params\n","0.403     Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c74254f6cb54d569f46ebbe0a3621cd","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"820c2164d24d4301a35d56ec446c9ee5","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"169082283e6946cf8f904a769ab16434","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"604473d54f6f4566b4f5cd1ee3917fb5","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Reducing learning rate. Best score: 0.004644975997507572, Current score: 0.010369626805186272\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d242b55cf46046a3972d1899e8c8b97c","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["c:\\Users\\nik\\miniconda3\\envs\\gpu2\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1b5b2f6234945818691ed1953e03fb3","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='4.002 MB of 4.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_loss</td><td>0.00731</td></tr><tr><td>trainer/global_step</td><td>1649</td></tr><tr><td>val_loss</td><td>0.01121</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">avid-feather-16</strong> at: <a href='https://wandb.ai/wattcast/SFH%20Load%20Forecasting/runs/v5fxjond' target=\"_blank\">https://wandb.ai/wattcast/SFH%20Load%20Forecasting/runs/v5fxjond</a><br/>Synced 6 W&B file(s), 4 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>.\\wandb\\run-20230403_110245-v5fxjond\\logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["run = wandb.init(project=\"SFH Load Forecasting\", reinit=True)\n","wandb_logger = WandbLogger(reinit=True)\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","enc = Encoder(input_size=input_chunk.shape[-1], hidden_size=HIDDEN_SIZE, num_layers=1)\n","dec = Decoder(input_size=input_chunk.shape[-1], hidden_size=HIDDEN_SIZE, num_layers=1)\n","model = Seq2Seq(enc, dec)\n","\n","lr_monitor = LRMonitor(monitor='val_loss', mode='min', factor=0.5, patience=2, min_lr=1e-6, verbose=True)\n","cbs = [EarlyStopping(monitor='val_loss'), lr_monitor]\n","trainer = pl.Trainer(max_epochs=100, logger = wandb_logger, gpus=1 if torch.cuda.is_available() else 0, callbacks=cbs)\n","trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trainer.test(model, test_loader)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Conclusion: \n","\n","We see that without teacher forcining the model is unable to learn from the data. \n","\n","Things to try next are:\n","\n","* Increase the number of epochs or the batch size during training to allow the model to learn more from the data.\n","\n","* Adjust the learning rate of the optimizer to help the model converge more quickly.\n","\n","* Experiment with different architectures or hyperparameters for the model, such as the number of layers or the dropout rate, to see if this improves performance.\n","\n","* Try using a different loss function, such as the mean absolute error (MAE) or DTW, to see if this helps the model better capture the patterns in the data.\n","\n","* Try one-shot approaches with attention ->"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9A_2CmwIA_Tf"},"source":["## Encoder-Decoder with Attention\n","\n","From the paper 'Learning to Align and Translate':\n","\n","https://arxiv.org/abs/1409.0473"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["class EncoderBahdanau(LightningModule):\n","\n","    def __init__(self,input_size, hidden_size):\n","        super().__init__()  \n","        self.hidden_size = hidden_size\n","        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, batch_first = True, bidirectional = True)\n","        self.fc = nn.Linear(hidden_size * 2, hidden_size)\n","\n","    def forward(self, input):    \n","        outputs, hidden = self.gru(input)  \n","        # the hiddens are stacked [forward_1, backward_1, forward_2, backward_2, ...]\n","        hidden_con = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n","        hidden = torch.tanh(self.fc(hidden_con))\n","        return outputs, hidden\n","    \n","\n","class Attention(LightningModule):\n","    def __init__(self, hidden_size):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.attn = nn.Linear(self.hidden_size * 3, self.hidden_size) # 3 for hidden size of decoder, encoder, and attention\n","        self.v = nn.Linear(self.hidden_size, 1, bias = False) # 1 for one attention value per time step\n","\n","    def forward(self, hidden, encoder_outputs):\n","        '''The idea here is to use the hidden state of the decoder at each time step to calculate the attention weights for each time step of the encoder output.'''\n","        # hidden = [batch size, hidden_size] of the decoder, which at t0 is the last hidden state of the encoder\n","        # encoder_outputs = [batch size, src len, enc hid dim * 2] because bidirectional\n","        N, src_len, _ = encoder_outputs.shape\n","        # repeat decoder hidden state src_len times to calculate attention weights\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        # encoder_outputs = [batch size, src len, enc hid dim * 2]\n","        # hidden = [batch size, src len, hidden_size]\n","        energy_input = torch.cat((hidden, encoder_outputs), dim = 2)\n","        energy = torch.tanh(self.attn(energy_input)) # (N, src_len, hidden_size)\n","        # energy = [batch size, src len, hidden_size]\n","        # now the energy is the input to the v layer, which is a linear layer with a single output\n","        attention = self.v(energy).squeeze(2) # (N, src_len),\n","        # attention= [batch size, src len]\n","        return F.softmax(attention, dim=1)\n","    \n","\n","class DecoderBahdanau(LightningModule):\n","    def __init__(self, output_size, hidden_size, dropout):\n","        super().__init__()\n","        self.output_size = output_size\n","        self.hidden_size = hidden_size\n","        self.dropout = dropout\n","        self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True)\n","        self.fc_out = nn.Linear(hidden_size * 2, output_size)\n","        self.dropout = nn.Dropout(dropout)\n","        self.attention = Attention(hidden_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["enc = EncoderBahdanau(3, 128)\n","\n","output, hidden = enc(input_chunk)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 2. Expected size 96 but got size 1 for tensor number 1 in the list.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[30], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m attention \u001b[39m=\u001b[39m att(hidden, output)\n\u001b[0;32m      5\u001b[0m dec \u001b[39m=\u001b[39m DecoderBahdanau(\u001b[39m1\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m output, hidden, attention \u001b[39m=\u001b[39m dec(output_chunk, hidden, output)\n","File \u001b[1;32mc:\\Users\\nik\\miniconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[1;32mIn[28], line 67\u001b[0m, in \u001b[0;36mDecoderBahdanau.forward\u001b[1;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[0;32m     64\u001b[0m weighted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mnsl, nbs -> nbl\u001b[39m\u001b[39m'\u001b[39m, encoder_outputs, attention_weights)\n\u001b[0;32m     65\u001b[0m \u001b[39m# weighted = [N, 1, hidden_size * 2]\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39m# now we can concatenate the weighted sum with the input\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m rnn_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((\u001b[39minput\u001b[39;49m, weighted), dim \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m)\n\u001b[0;32m     68\u001b[0m \u001b[39m# rnn_input = [N, 1, input_size + hidden_size * 2]\u001b[39;00m\n\u001b[0;32m     69\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(rnn_input, hidden)\n","\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 96 but got size 1 for tensor number 1 in the list."]}],"source":["att = Attention(128)\n","\n","attention = att(hidden, output)\n","\n","dec = DecoderBahdanau(1, 128, 0.1)\n","\n","output, hidden, attention = dec(output_chunk, hidden, output)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"Jb6qiiRO9HcZ"},"outputs":[],"source":["class EncoderBad(nn.Module):\n","\n","    def __init__(self,input_size, hidden_size):\n","        super(EncoderBad, self).__init__()  \n","        self.hidden_size = hidden_size\n","        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, batch_first = True, bidirectional = True)\n","        self.fc = nn.Linear(hidden_size * 2, hidden_size)\n","\n","    def forward(self, input):    \n","        outputs, hidden = self.gru(input)  \n","\n","        hidden_con = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n","        hidden = torch.tanh(self.fc(hidden_con))\n","\n","        print(hidden.shape)\n","        return outputs, hidden\n","\n","class Attention(nn.Module):\n","  def __init__(self, hidden_size):\n","    super(Attention, self).__init__()\n","\n","    self.attn = nn.Linear(hidden_size * 3, hidden_size)\n","    self.v = nn.Linear(hidden_size, 1, bias = False)\n","\n","  def forward(self, hidden, encoder_outputs):\n","\n","    batch_size = encoder_outputs.shape[0]\n","    src_len = encoder_outputs.shape[1]\n","\n","    hidden = hidden.unsqueeze(1).repeat(1, src_len, 1) #we open up the hidden tensor at index 1, and repeat it src length time at this index\n","\n","    energy_input = torch.cat((hidden, encoder_outputs), dim = 2)\n","\n","    energy = torch.tanh(self.attn(energy_input))\n","    attention = self.v(energy)\n","\n","    return F.softmax(attention, dim = 1).squeeze(-1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eu7RyX0KLeJj"},"outputs":[],"source":["class DecoderBad(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, attention):\n","      super(DecoderBad, self).__init__()   \n","      \n","      self.output_size = output_size\n","      self.attention = attention\n","      \n","      self.hidden_size = hidden_size\n","      self.gru = nn.GRU(input_size=hidden_size * 2 + input_size,  hidden_size=hidden_size, batch_first = True)\n","      self.fc_out = nn.Linear(hidden_size*3 + input_size, output_size)\n","  \n","    def forward(self, input, hidden, encoder_outputs):\n","\n","\n","      # encoder_outputs = [batch_size, src_len, hidden_size * 2]\n","      # hidden = [batch_size, hidden_size]\n","      # input = [batch_size] only one word / number per timestep\n","\n","      input = input.unsqueeze(-1)\n","      \n","      # input = [batch_size, 1]\n","\n","      # a = [batch_size, src_len]\n","      a = self.attention(hidden, encoder_outputs)\n","      a = a.unsqueeze(1) \n","      # a = [batch_size,1, src_len]\n","\n","      weighted = torch.einsum('bki, bjh-> bkh',[a,encoder_outputs])\n","      #weighted = [batch_size, 1, 2*hidden_size]\n","\n","      rnn_input = torch.cat((input, weighted), dim = 2)\n","\n","\n","      #rnn_input = [batch_size, 1, hidden_size * 2 + input_size]\n","\n","      output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n","\n","\n","      prediction = self.fc_out(torch.cat((output, weighted, input), dim = 2)).squeeze(-1)\n","\n","\n","      return prediction, hidden.squeeze(0)\n"]},{"cell_type":"markdown","metadata":{"id":"4aS9xB-MyRJb"},"source":["# Convolutional Seq2Seq\n","\n","https://arxiv.org/abs/1705.03122"]},{"cell_type":"markdown","metadata":{"id":"clVlGhAcWz2p"},"source":["### Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6vBiRNCGPoI"},"outputs":[],"source":["class EncoderConv(nn.Module):\n","  def __init__(self, input_size, emb_size, hid_size, n_layers, kernel_size, dropout, device, max_length= 100):\n","    super(EncoderConv, self).__init__()\n","\n","    assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\n","\n","    self.device = device\n","    # The scale variable is used by the authors to \"ensure that the variance\n","    # throughout the network does not change dramatically\".\n","    # The performance of the model seems to vary wildly\n","    # using different seeds if this is not used.\n","    self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device) # ~0.7\n","    self.tok_emb = nn.Linear(input_size,emb_size)\n","    self.pos_emb = nn.Embedding(max_length, emb_size)\n","    self.emb2hid = nn.Linear(emb_size, hid_size)\n","    self.hid2emb = nn.Linear(hid_size, emb_size)\n","    self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_size,\n","                                          out_channels = 2*hid_size,\n","                                          kernel_size = kernel_size,\n","                                          padding = (kernel_size -1) // 2\n","                                          )\n","                                for _ in range(n_layers)])\n","    self.dropout = nn.Dropout(dropout)\n","\n","\n","  def forward(self, src):\n","    batch_size = src.shape[0]\n","    src_len = src.shape[1]\n","\n","    #pos = [batch_size, src_len] (of the longest seq in the batch)\n","    pos = torch.arange(0,src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","\n","    tok_embedded = self.tok_emb(src)\n","    pos_embedded = self.pos_emb(pos)\n","\n","    #element-wise summing of embeddings\n","    #embedded = [batch_size, src_len, emb_size]\n","    embedded = self.dropout(tok_embedded + pos_embedded)\n","\n","    #conv_input = [batch_size, src_len, hidden_size]\n","    conv_input = self.emb2hid(embedded)\n","\n","    conv_input = torch.einsum('ijk->ikj', conv_input)\n","\n","    # conv likes dims = [batch_size, hidden_size, src_len]; n = batches, C_in = channels / hidden, L = length\n","    # https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n","    for i, conv in enumerate(self.convs):\n","\n","      conved = conv(self.dropout(conv_input))\n","\n","      conved = F.glu(conved, dim = 1) # 1 (k) dim is now [hidden_size * 2]\n","\n","      #residual\n","\n","      #print(self.scale)\n","      conved = (conved + conv_input) * self.scale # \n","\n","      conv_input = conved\n","\n","\n","    conved = torch.einsum('ikj->ijk', conved)\n","    conved = self.hid2emb(conved)\n","\n","    combined = (conved + embedded) * self.scale\n","\n","    return conved, combined\n","\n","\n","\n","\n","                                                    \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cc2eVF8qSQnY"},"outputs":[],"source":["enc_conv = EncoderConv(input_size=1, emb_size=1, hid_size=3, n_layers=2, kernel_size= 3, dropout = 0.5, device = device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669120724939,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"fCOP0M09SYmo","outputId":"a7743648-3e59-4b88-f420-a11eb163a08e"},"outputs":[{"data":{"text/plain":["torch.Size([8, 48, 1])"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["conved, combined = enc_conv(src)\n"]},{"cell_type":"markdown","metadata":{"id":"8XylnsnuWxcw"},"source":["### Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CloxXBmPSzAx"},"outputs":[],"source":["class DecoderConv(nn.Module):\n","\n","  def __init__(self,\n","               input_size,\n","               emb_size,\n","               hid_size,\n","               output_size,\n","               n_layers,\n","               kernel_size,\n","               dropout,\n","               trg_pad_idx,\n","               device, \n","               max_length=100):\n","    \n","    super(DecoderConv, self).__init__()\n","    \n","    self.device = device\n","    self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device) # ~0.7\n","    self.input_size = input_size\n","    self.hid_size = hid_size\n","    self.kernel_size = kernel_size\n","    self.trg_pad_idx = trg_pad_idx\n","\n","    self.dropout = nn.Dropout(dropout)\n","    self.tok_emb = nn.Linear(input_size, emb_size)\n","    self.pos_emb = nn.Embedding(max_length, emb_size)\n","    self.emb2hid = nn.Linear(emb_size, hid_size)\n","    self.hid2emb = nn.Linear(hid_size, emb_size)\n","    self.att_hid2emb = nn.Linear(hid_size, emb_size)\n","    self.att_emb2hid = nn.Linear(emb_size, hid_size)\n","    self.fc_out = nn.Linear(emb_size, output_size)\n","\n","\n","    self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_size,\n","                                          out_channels = 2*hid_size,\n","                                          kernel_size = kernel_size\n","                                          )\n","                                for _ in range(n_layers)])\n","\n","\n","\n","  def calc_att(self, embedded, conved, encoder_conved, encoder_combined):\n","\n","    \n","    #encoder_conved = [N, src, emb]\n","    #encoder_combined = [N, src, emb]\n","\n","    #conved; it comes out [N, hid_size, trg] from the conv1d layer \n","    conved_permuted = torch.einsum('nht->nth', conved)\n","    # -> [N, trg, hid]\n","\n","\n","    conved_emb = self.att_hid2emb(conved_permuted)\n","    # [N, trg, emb]\n","\n","    combined = (conved_emb + embedded) * self.scale\n","\n","    encoder_conved_perm = torch.einsum('nse->nes', encoder_conved)\n","\n","    energy = torch.einsum('nte,nes->nts', [combined, encoder_conved_perm])\n","\n","    attention = F.softmax(energy, dim = 2) #over the source dimension, because later the encoders are weighted\n","\n","    attended_encoding = torch.einsum('nts, nse->nte', attention, encoder_combined)\n","\n","    attended_encoding = self.att_emb2hid(attended_encoding)\n","    #[N, trg, hid]\n","\n","    attended_combined = (attended_encoding.permute(0,2,1) + conved) * self.scale\n","\n","\n","    return attention, attended_combined\n","\n","\n","\n","  def forward(self, trg, encoder_conved, encoder_combined):\n","\n","    batch_size = trg.shape[0]\n","    trg_len = trg.shape[1]\n","\n","    pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","\n","    tok_embedded = self.tok_emb(trg)\n","    pos_embedded = self.pos_emb(pos)\n","\n","    embedded = self.dropout(tok_embedded + pos_embedded)\n","\n","    conv_input = self.emb2hid(embedded)\n","\n","    conv_input = torch.einsum('nth->nht', conv_input)\n","\n","    for i, conv in enumerate(self.convs):\n","\n","      conv_input = self.dropout(conv_input)\n","\n","      # padding\n","      padding = torch.zeros(batch_size, self.hid_size, self.kernel_size -1).fill_(self.trg_pad_idx).to(self.device)\n","\n","      padded_conv_input = torch.cat((padding, conv_input), dim = 2)\n","      # [N, h, t+k-1]\n","\n","      conved = conv(padded_conv_input)\n","      # [N, 2*h, t]\n","\n","      conved = F.glu(conved, dim = 1) #glu halves the dimension, this is why we setup the convs that way\n","\n","      # [N, h , t]\n","\n","      attention, conved = self.calc_att(embedded, conved, encoder_conved, encoder_combined)\n","      # att: [N, t, s]\n","      #conved: [N, h, t]\n","\n","      conved = (conved + conv_input) * self.scale\n","\n","      conv_input = conved #pass to the next layer\n","\n","\n","    conved = self.hid2emb(conved.permute(0,2,1))\n","    # [N, t, e]\n","\n","    output = self.fc_out(self.dropout(conved))\n","    # [N, t, 1]\n","\n","    return output, attention\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1669122496281,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"Ey48-WHo5Sgo","outputId":"c3a1f31b-c01e-48ac-e061-3c1636e54c64"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  after removing the cwd from sys.path.\n"]}],"source":["\n","batch = iter(trainloader).next()\n","src, trg = batch\n","src = torch.tensor(src, dtype=torch.float32).to(device)\n","trg = torch.tensor(trg, dtype=torch.float32).to(device)\n","\n","\n","\n","dec = DecoderConv(\n","               input_size = 1,\n","               emb_size = 1,\n","               hid_size = 3,\n","               output_size = 1,\n","               n_layers= 2,\n","               kernel_size=3,\n","               dropout=0.1,\n","               trg_pad_idx= 1,\n","               device=device, \n","               max_length=100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKKOln8YWgFP"},"outputs":[],"source":["output, attn = dec(trg, conved, combined)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDsmWD1EXVuU"},"outputs":[],"source":["class Seq2SeqConv(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        \n","    def forward(self, src, trg):\n","        \n","        #src = [batch size, src len]\n","        #trg = [batch size, trg len - 1] (<eos> token sliced off the end)\n","           \n","        #calculate z^u (encoder_conved) and (z^u + e) (encoder_combined)\n","        #encoder_conved is output from final encoder conv. block\n","        #encoder_combined is encoder_conved plus (elementwise) src embedding plus \n","        #  positional embeddings \n","        encoder_conved, encoder_combined = self.encoder(src)\n","            \n","        #encoder_conved = [batch size, src len, emb dim]\n","        #encoder_combined = [batch size, src len, emb dim]\n","        \n","        #calculate predictions of next words\n","        #output is a batch of predictions for each word in the trg sentence\n","        #attention a batch of attention scores across the src sentence for \n","        #  each word in the trg sentence\n","        output, attention = self.decoder(trg, encoder_conved, encoder_combined)\n","        \n","        #output = [batch size, trg len - 1, output dim]\n","        #attention = [batch size, trg len - 1, src len]\n","        \n","        return output, attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZNY32j7XdLUK"},"outputs":[],"source":["TRG_PAD_IDX = 1e-10\n","\n","\n","enc_conv = EncoderConv(input_size=1,\n","                       emb_size=1,\n","                       hid_size=3,\n","                       n_layers=2, \n","                       kernel_size= 3,\n","                       dropout = 0.5, \n","                       device = device)\n","\n","dec_conv = DecoderConv(\n","               input_size = 1,\n","               emb_size = 1,\n","               hid_size = 3,\n","               output_size = 1,\n","               n_layers= 2,\n","               kernel_size=3,\n","               dropout=0.1,\n","               trg_pad_idx= TRG_PAD_IDX,\n","               device=device, \n","               max_length=100)\n","\n","model_conv = Seq2SeqConv(enc_conv, dec_conv).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":877,"status":"ok","timestamp":1669122747518,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"-LYE_6kvdapt","outputId":"db0212b4-4c01-4869-b383-f53496643fd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 476 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model_conv):,} trainable parameters')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FolC6hBcdsDC"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SE9Py5ecli_1"},"outputs":[],"source":["def generate_square_subsequent_mask(dim1: int, dim2: int):\n","    \"\"\"\n","    Generates an upper-triangular matrix of -inf, with zeros on diag.\n","    Modified from: \n","    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n","    Args:\n","        dim1: int, for both src and tgt masking, this must be target sequence\n","              length\n","        dim2: int, for src masking this must be encoder sequence length (i.e. \n","              the length of the input sequence to the model), \n","              and for tgt masking, this must be target sequence length \n","    Return:\n","        A Tensor of shape [dim1, dim2]\n","    \"\"\"\n","    return torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1669124758583,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"UfssyVUoljwQ","outputId":"b1339f86-7e33-4d88-d0f8-9b6f7a3858f4"},"outputs":[{"data":{"text/plain":["tensor([[0., -inf, -inf],\n","        [0., 0., -inf],\n","        [0., 0., 0.]])"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["generate_square_subsequent_mask(3,3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPdoNCdglpjw"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["cylh-CMwV9wB","9A_2CmwIA_Tf"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"gpu2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"2d017bf32283ba7f67b14df218f7d5e330099bbfa9a17c2165be9519c3d88acb"}}},"nbformat":4,"nbformat_minor":0}
=======
{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"0vmDOXcru6CH"},"source":["# 1 - Seq2Seq with Neural Networks for Household Load Data"]},{"cell_type":"markdown","metadata":{"id":"anXQdBx1u6CL"},"source":["## Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6109,"status":"ok","timestamp":1670944368236,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"9WoPuZYZu6CM"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.8.dylib\n","  Referenced from: /Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torchvision/image.so\n","  Reason: tried: '/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/bin/../lib/libjpeg.8.dylib' (no such file), '/usr/local/lib/libjpeg.8.dylib' (no such file), '/usr/lib/libjpeg.8.dylib' (no such file)\n","  warn(f\"Failed to load image Python extension: {e}\")\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os, sys\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","import torch.optim as optim\n","import pytorch_lightning as pl\n","from pytorch_lightning import LightningModule\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from pytorch_lightning.loggers import WandbLogger\n","from PIL import Image\n","from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n","from io import BytesIO\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","#import plotly.express as px\n","\n","from scipy.stats import boxcox\n","\n","\n","import wandb\n","wandb.login()\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class ElectricalLoadDataset(Dataset):\n","    def __init__(self, data_dir, \n","                input_chunk_size,\n","                output_chunk_size, \n","                scaler = None,\n","                timeenc=False,\n","                split='train', \n","                train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, SFH = -1, boxcox_trafo=False):\n","        \n","        \n","        self.input_chunk_size = input_chunk_size\n","        self.output_chunk_size = output_chunk_size\n","        self.scaler = scaler\n","        self.timeenc = timeenc\n","        self.SFH = SFH\n","        self.boxcox_trafo = boxcox_trafo\n","\n","        load_series = self._load_data(data_dir)\n","\n","        if self.scaler is None and split == 'train':\n","            self.scaler = MinMaxScaler()\n","            self.scaler.fit(load_series[:int(train_ratio * len(load_series))])\n","\n","        if split == 'train':\n","            self.load_series = self.scaler.transform(load_series[:int(train_ratio * len(load_series))])\n","        elif split == 'val':\n","            self.load_series = self.scaler.transform(load_series[int(train_ratio * len(load_series)):int((train_ratio + val_ratio) * len(load_series))])\n","        elif split == 'test':\n","            self.load_series = self.scaler.transform(load_series[int((train_ratio + val_ratio) * len(load_series)):])\n","\n","\n","    def __len__(self):\n","        return len(self.load_series) - self.input_chunk_size - self.output_chunk_size + 1\n","\n","    def __getitem__(self, idx):\n","        input_chunk = self.load_series[idx:idx+self.input_chunk_size]\n","        output_chunk = self.load_series[idx+self.input_chunk_size:idx+self.input_chunk_size+self.output_chunk_size]\n","        if self.boxcox_trafo:\n","            input_chunk = self.boxy(input_chunk)\n","            output_chunk = self.boxy(output_chunk)\n","\n","\n","        return input_chunk, output_chunk\n","\n","    def _load_data(self, data_dir):\n","        df = pd.read_csv(os.path.join(data_dir, 'load_data_15min_watts.csv'), index_col=0, parse_dates=True)[:int(1e4)]\n","        df = df.iloc[:, [self.SFH]]\n","        if self.timeenc == 1:\n","            df = self.timeenc_1(df)\n","        elif self.timeenc == 2:\n","            df = self.timeenc_2(df)\n","\n","        return df.values\n","            \n","    def timeenc_1(self, df):\n","        # minute of the day\n","        df['minute'] = df.index.hour * 60 + df.index.minute\n","        # day of the week\n","        df['dayofweek'] = df.index.dayofweek\n","        return df\n","    \n","    def timeenc_2(self, df):\n","        #trigonometric encoding\n","        df['sin_time'] = np.sin(2*np.pi*(df.index.minute/60 + df.index.hour/24))\n","        df['cos_time'] = np.cos(2*np.pi*(df.index.minute/60 + df.index.hour/24))\n","        return df\n","    \n","    #TODO: fix bug here\n","    def boxy(self, sample):\n","        '''This function applies the boxcox transformation to the input and output chunks.'''\n","        data_transformed = np.zeros_like(sample)\n","        block_size, input_len = sample.shape\n","        # make data positive\n","        # apply boxcox transformation\n","        transformed, _ = boxcox(sample[:,:1].reshape(-1) + 1e-6)\n","        scaler = MinMaxScaler()\n","        transformed = scaler.fit_transform(transformed.reshape(-1,1))\n","        \n","        #make bx into shape (96,1)\n","        data_transformed[:,:1] = transformed.reshape(block_size,1)\n","        return data_transformed\n","\n","\n","    \n","class ElectricalLoadDataLoader(DataLoader):\n","    def __init__(self, *args, **kwargs):\n","        super(ElectricalLoadDataLoader, self).__init__(*args, **kwargs)\n","        self.collate_fn = self.collate_fn_\n","\n","    def collate_fn_(self, batch):\n","        input_chunks, output_chunks = zip(*batch)\n","        input_tensor = torch.FloatTensor(input_chunks)\n","        output_tensor = torch.FloatTensor(output_chunks)\n","        return input_tensor, output_tensor\n","    "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train = ElectricalLoadDataset(data_dir='../data', input_chunk_size=96, output_chunk_size=96, split='train', train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, timeenc=1, boxcox_trafo=False)\n","train_loader = ElectricalLoadDataLoader(train, batch_size=16, shuffle=True)\n","val = ElectricalLoadDataset(data_dir='../data', scaler = train.scaler, input_chunk_size=96, output_chunk_size=96, split='val', train_ratio=0.8, val_ratio=0.1, test_ratio=0.1,  timeenc=1,boxcox_trafo=False)\n","val_loader = ElectricalLoadDataLoader(val, batch_size=16, shuffle=True)\n","test = ElectricalLoadDataset(data_dir='../data', scaler = train.scaler, input_chunk_size=96, output_chunk_size=96, split='test', train_ratio=0.8, val_ratio=0.1, test_ratio=0.1,  timeenc=1,boxcox_trafo=False)\n","test_loader = ElectricalLoadDataLoader(test, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 96, 3]) torch.Size([16, 96, 3])\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/35/267ql_w95qlgmrzwgprns44w0000gn/T/ipykernel_70829/1240816308.py:92: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/miniforge3/conda-bld/pytorch-recipe_1675740388473/work/torch/csrc/utils/tensor_new.cpp:233.)\n","  input_tensor = torch.FloatTensor(input_chunks)\n"]}],"source":["for i , (input_chunk, output_chunk) in enumerate(train_loader):\n","    print(input_chunk.shape, output_chunk.shape)\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["## The classic Seq2Seq model with a GRU encoder and decoder \n","\n","(Sutskever et al. 2014)\n","https://arxiv.org/abs/1409.3215"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class Encoder(LightningModule):\n","    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.dropout = dropout\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        \n","    def forward(self, x):\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n","        out, hidden = self.gru(x, h0)\n","        return out, hidden\n","    \n","\n","class Decoder(LightningModule):\n","    def __init__(self, input_size, hidden_size, num_layers):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, input_size)\n","\n","\n","    def forward(self, x, hidden):\n","        out, hidden = self.gru(x, hidden)\n","        out = self.fc(out)\n","        return out, hidden\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class Seq2Seq(LightningModule):\n","    \n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        N, _, _ = src.shape\n","        N, output_chunk_size , output_size = trg.shape\n","        outputs = torch.zeros(N, output_chunk_size, output_size).to(self.device)\n","        out, hidden = self.encoder(src)\n","        inp = src[:,-1,:].unsqueeze(1)\n","        \n","        for t in range(0, output_chunk_size):\n","            output, hidden = self.decoder(inp, hidden)\n","            outputs[:,t,:] = output.squeeze(1)\n","            teacher_force = np.random.random() < teacher_forcing_ratio\n","            if self.training and teacher_force:\n","                inp = trg[:,t,:].unsqueeze(1)\n","            else:\n","                inp = output\n","        return outputs\n","\n","    def training_step(self, batch):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('train_loss', loss)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('val_loss', loss)\n","        if batch_idx == 0:\n","            buffers = self._plot_predictions(output, trg)\n","            # Combine the image buffers into a single image\n","            images = [np.array(Image.open(buffer)) for buffer in buffers]\n","            combined_image = np.concatenate(images, axis=1)\n","            # Log the combined image to WandB\n","            wandb.log({\"predictions_val_dataset\": wandb.Image(combined_image)})\n","        return loss\n","    \n","    def test_step(self, batch, batch_idx):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('test_loss', loss)\n","        if batch_idx == 0:\n","            buffers = self._plot_predictions(output, trg)\n","            # Combine the image buffers into a single image\n","            images = [np.array(Image.open(buffer)) for buffer in buffers]\n","            combined_image = np.concatenate(images, axis=1)\n","            # Log the combined image to WandB\n","            wandb.log({\"predictions_test_dataset\": wandb.Image(combined_image)})\n","        return loss\n","        \n","    def _plot_predictions(self, preds, actuals):\n","        preds = preds.detach().cpu().numpy()\n","        actuals = actuals.detach().cpu().numpy()\n","        buffers = []\n","        for i in range(preds.shape[0]):\n","            fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n","            # plotting the i-th sequence in the batch\n","            ax.plot(preds[i, :, 0], label='Predictions')\n","            ax.plot(actuals[i, :, 0], label='Actuals')\n","            ax.legend()\n","            # Convert the figure to an image buffer\n","            canvas = FigureCanvas(fig)\n","            buffer = BytesIO()\n","            canvas.print_figure(buffer, format='png')\n","            buffer.seek(0)\n","            # Close the figure to save memory\n","            plt.close(fig)\n","            # Append the image buffer to the list of buffers\n","            buffers.append(buffer)\n","        # Return the list of image buffers\n","        return buffers\n","\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=1e-3)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","enc = Encoder(input_size=3, hidden_size=128, num_layers=1, dropout=0.2)\n","dec = Decoder(input_size=3, hidden_size=128, num_layers=1)\n","model = Seq2Seq(enc, dec)\n","wandb_logger = WandbLogger(project = 'SFH Load Forecasting', name = \"GRU_timeenc\")\n","\n","cbs = [EarlyStopping(monitor='val_loss')]\n","trainer = pl.Trainer(max_epochs=20, logger = wandb_logger, gpus=1 if torch.cuda.is_available() else 0, callbacks=cbs)\n","trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","c:\\Users\\nik\\miniconda3\\envs\\gpu2\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e301fb5edfac4cfe9307696286428c0f","version_major":2,"version_minor":0},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","       Test metric             DataLoader 0\n","\n","        test_loss           0.17294490337371826\n","\n"]},{"data":{"text/plain":["[{'test_loss': 0.17294490337371826}]"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["trainer.test(model, test_loader)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Conclusion: \n","\n","We see that without teacher forcining the model is unable to learn from the data. \n","\n","Things to try next are:\n","\n","* Increase the number of epochs or the batch size during training to allow the model to learn more from the data.\n","\n","* Adjust the learning rate of the optimizer to help the model converge more quickly.\n","\n","* Experiment with different architectures or hyperparameters for the model, such as the number of layers or the dropout rate, to see if this improves performance.\n","\n","* Try using a different loss function, such as the mean absolute error (MAE) or DTW, to see if this helps the model better capture the patterns in the data.\n","\n","* Try one-shot, non recurrent approaches -> transformer"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9A_2CmwIA_Tf"},"source":["## Encoder-Decoder with Attention\n","\n","From the paper 'Learning to Align and Translate':\n","\n","https://arxiv.org/abs/1409.0473"]},{"cell_type":"code","execution_count":194,"metadata":{},"outputs":[],"source":["class EncoderBahdanau(LightningModule):\n","\n","    def __init__(self,input_size, hidden_size):\n","        super().__init__()  \n","        self.hidden_size = hidden_size\n","        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, batch_first = True, bidirectional = True)\n","        self.fc = nn.Linear(hidden_size * 2, hidden_size) # 2 for bidirection\n","\n","    def forward(self, input):    \n","        outputs, hidden = self.gru(input)  \n","        #outputs = [batch size, seq len, hid dim * num directions]\n","        #hidden = [batch size, num layers * num directions, hid dim]\n","        # the hiddens are stacked [forward_1, backward_1, forward_2, backward_2, ...]\n","        # we use the last two layers, and have to reshape it to be (batch_size, 2, hidden_size)\n","        hidden_con = hidden[-2:,:,:].permute(1, 0, 2).contiguous().view(input.shape[0], -1)\n","        hidden = torch.tanh(self.fc(hidden_con))\n","        return outputs, hidden\n","    \n","\n","class Attention(LightningModule):\n","    def __init__(self, hidden_size):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.attn = nn.Linear(self.hidden_size * 3, self.hidden_size) # 3 for hidden size of decoder, encoder, and attention\n","        self.v = nn.Linear(self.hidden_size, 1, bias = False) # 1 for one attention value per time step\n","\n","    def forward(self, hidden, encoder_outputs):\n","        '''The idea here is to use the hidden state of the decoder at each time step to calculate the attention weights for each time step of the encoder output.'''\n","        # hidden = [batch size, hidden_size] of the decoder, which at t0 is the last hidden state of the encoder\n","        # encoder_outputs = [batch size, src len, enc hid dim * 2] because bidirectional\n","        N, src_len, _ = encoder_outputs.shape\n","        # repeat decoder hidden state src_len times to calculate attention weights\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        # encoder_outputs = [batch size, src len, enc hid dim * 2]\n","        # hidden = [batch size, src len, hidden_size]\n","        energy_input = torch.cat((hidden, encoder_outputs), dim = 2)\n","        energy = torch.tanh(self.attn(energy_input)) # (N, src_len, hidden_size)\n","        # energy = [batch size, src len, hidden_size]\n","        # now the energy is the input to the v layer, which is a linear layer with a single output\n","        attention = self.v(energy).squeeze(2) # (N, src_len), this basically transforms the energy to a single value for each time step\n","        # attention= [batch size, src len]\n","        return F.softmax(attention, dim=1)\n","    \n","\n","class DecoderBahdanau(LightningModule):\n","    '''For the decoder, we will use the attention mechanism to calculate the context vector,\n","    which is a weighted sum of the encoder outputs, based on the attention weights. \n","    The context vector is then concatenated with the decoder input and passed through the GRU.'''\n","    def __init__(self, input_size, hidden_size):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.gru = nn.GRU(2*hidden_size + input_size, hidden_size, batch_first = True)\n","        self.fc_out = nn.Linear(hidden_size * 3 + input_size, 1)\n","        self.attention = Attention(hidden_size)\n","\n","    def forward(self, inp, hidden, encoder_outputs):\n","        # input = [N]\n","        # hidden = [N, hidden_size]\n","        # encoder_outputs = [N, src_len, hidden_size * 2]\n","\n","        a = self.attention(hidden, encoder_outputs) # (N, src_len)\n","        a = a.unsqueeze(1) # (N, 1, src_len)\n","\n","        weighted = torch.einsum('nis,nsk->nik', a, encoder_outputs) # (N, 1, hidden_size * 2)')\n","\n","        #inp = inp.unsqueeze(1) # (N, 1, input_size)\n","\n","        rnn_input = torch.cat((inp, weighted), dim = 2) # (1, N, hidden_size * 3)\n","\n","        output, hidden = self.gru(rnn_input, hidden.unsqueeze(0))\n","\n","        inp, output, weighted = inp.squeeze(1), output.squeeze(1), weighted.squeeze(1)\n","\n","        prediction_input = torch.cat((inp, output, weighted), dim = 1) # (N, hidden_size * 3 + input_size)\n","        \n","        prediction = self.fc_out(prediction_input) # (N, 1)\n","\n","        return prediction, hidden.squeeze(0)"]},{"cell_type":"markdown","metadata":{},"source":["### Seq2Seq Model Adjusted for Bahdanau Attention"]},{"cell_type":"code","execution_count":261,"metadata":{},"outputs":[],"source":["class Seq2SeqBahdenau(LightningModule):\n","    \n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        N, _, _ = src.shape\n","        N, output_chunk_size , _ = trg.shape\n","        outputs = torch.zeros(N, output_chunk_size).to(self.device)\n","        encoder_outputs, hidden = self.encoder(src)\n","        inp = src[:,-1,:].unsqueeze(1)\n","\n","        print(output_chunk_size)\n","        \n","        for t in range(0, output_chunk_size):\n","            output, hidden = self.decoder(inp, hidden, encoder_outputs)\n","            print(outputs.shape)\n","            print(output.shape)\n","            outputs[:,t] = output.squeeze(1)\n","            teacher_force = np.random.random() < teacher_forcing_ratio\n","            if self.training and teacher_force:\n","                inp = trg[:,t,:].unsqueeze(1)\n","            else:\n","                inp = output\n","        return outputs\n","\n","    def training_step(self, batch):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('train_loss', loss)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('val_loss', loss)\n","        if batch_idx == 0:\n","            buffers = self._plot_predictions(output, trg)\n","            # Combine the image buffers into a single image\n","            images = [np.array(Image.open(buffer)) for buffer in buffers]\n","            combined_image = np.concatenate(images, axis=1)\n","            # Log the combined image to WandB\n","            wandb.log({\"predictions_val_dataset\": wandb.Image(combined_image)})\n","        return loss\n","    \n","    def test_step(self, batch, batch_idx):\n","        src, trg = batch\n","        output = self(src, trg)\n","        loss = F.mse_loss(output, trg)\n","        self.log('test_loss', loss)\n","        if batch_idx == 0:\n","            buffers = self._plot_predictions(output, trg)\n","            # Combine the image buffers into a single image\n","            images = [np.array(Image.open(buffer)) for buffer in buffers]\n","            combined_image = np.concatenate(images, axis=1)\n","            # Log the combined image to WandB\n","            wandb.log({\"predictions_test_dataset\": wandb.Image(combined_image)})\n","        return loss\n","        \n","    def _plot_predictions(self, preds, actuals):\n","        preds = preds.detach().cpu().numpy()\n","        actuals = actuals.detach().cpu().numpy()\n","        buffers = []\n","        for i in range(preds.shape[0]):\n","            fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n","            # plotting the i-th sequence in the batch\n","            ax.plot(preds[i, :, 0], label='Predictions')\n","            ax.plot(actuals[i, :, 0], label='Actuals')\n","            ax.legend()\n","            # Convert the figure to an image buffer\n","            canvas = FigureCanvas(fig)\n","            buffer = BytesIO()\n","            canvas.print_figure(buffer, format='png')\n","            buffer.seek(0)\n","            # Close the figure to save memory\n","            plt.close(fig)\n","            # Append the image buffer to the list of buffers\n","            buffers.append(buffer)\n","        # Return the list of image buffers\n","        return buffers\n","\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=1e-3)"]},{"cell_type":"code","execution_count":262,"metadata":{},"outputs":[],"source":["enc = EncoderBahdanau(3, 128)\n","\n","output, hidden = enc(input_chunk)"]},{"cell_type":"code","execution_count":263,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([16, 96])"]},"execution_count":263,"metadata":{},"output_type":"execute_result"}],"source":["att = Attention(128)\n","\n","attention = att(hidden, output)\n","\n","attention.shape"]},{"cell_type":"code","execution_count":264,"metadata":{},"outputs":[],"source":["\n","dec = DecoderBahdanau(3, 128)\n","prediction, hidden = dec(output_chunk[:,:1,:], hidden, output)"]},{"cell_type":"code","execution_count":265,"metadata":{},"outputs":[],"source":["model_test = Seq2SeqBahdenau(enc, dec)"]},{"cell_type":"code","execution_count":266,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["96\n","torch.Size([16, 96])\n","torch.Size([16, 1])\n","torch.Size([16, 96])\n","torch.Size([16, 1])\n","torch.Size([16, 96])\n","torch.Size([16, 1])\n","torch.Size([16, 96])\n","torch.Size([16, 1])\n"]},{"ename":"IndexError","evalue":"Dimension out of range (expected to be in range of [-2, 1], but got 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[266], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_test(input_chunk, output_chunk)\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[261], line 18\u001b[0m, in \u001b[0;36mSeq2SeqBahdenau.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(output_chunk_size)\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, output_chunk_size):\n\u001b[0;32m---> 18\u001b[0m     output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(inp, hidden, encoder_outputs)\n\u001b[1;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(outputs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[194], line 68\u001b[0m, in \u001b[0;36mDecoderBahdanau.forward\u001b[0;34m(self, inp, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     64\u001b[0m weighted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mnis,nsk->nik\u001b[39m\u001b[39m'\u001b[39m, a, encoder_outputs) \u001b[39m# (N, 1, hidden_size * 2)')\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m#inp = inp.unsqueeze(1) # (N, 1, input_size)\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m rnn_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((inp, weighted), dim \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m) \u001b[39m# (1, N, hidden_size * 3)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(rnn_input, hidden\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[1;32m     72\u001b[0m inp, output, weighted \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m), output\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m), weighted\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n","\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"]}],"source":["model_test(input_chunk, output_chunk)"]},{"cell_type":"markdown","metadata":{"id":"Eu7RyX0KLeJj"},"source":["### Trying out the model"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n","  rank_zero_warn(\n","/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n","  rank_zero_deprecation(\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","\n","  | Name    | Type            | Params\n","--------------------------------------------\n","0 | encoder | EncoderBahdanau | 135 K \n","1 | decoder | DecoderBahdanau | 199 K \n","--------------------------------------------\n","334 K     Trainable params\n","0         Non-trainable params\n","334 K     Total params\n","1.337     Total estimated model params size (MB)\n"]},{"name":"stdout","output_type":"stream","text":["Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n","  rank_zero_warn(\n","/Users/nikolaushouben/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"name":"stdout","output_type":"stream","text":["torch.Size([16, 256])\n"]},{"ename":"RuntimeError","evalue":"Tensors must have same number of dimensions: got 4 and 3","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[174], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m cbs \u001b[39m=\u001b[39m [EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m      8\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, logger \u001b[39m=\u001b[39m wandb_logger, gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m, callbacks\u001b[39m=\u001b[39mcbs)\n\u001b[0;32m----> 9\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model_bahdenau, train_dataloaders\u001b[39m=\u001b[39;49mtrain_loader, val_dataloaders\u001b[39m=\u001b[39;49mval_loader)\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    610\u001b[0m )\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1114\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1204\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1203\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1206\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1276\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1276\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1280\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    151\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 152\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    154\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    136\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    138\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m    the outputs of the step\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 234\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(hook_name, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m output\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1494\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1494\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1496\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[1;32m    389\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","Cell \u001b[0;32mIn[172], line 34\u001b[0m, in \u001b[0;36mSeq2SeqBahdenau.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m     33\u001b[0m     src, trg \u001b[39m=\u001b[39m batch\n\u001b[0;32m---> 34\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(src, trg)\n\u001b[1;32m     35\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(output, trg)\n\u001b[1;32m     36\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, loss)\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[172], line 16\u001b[0m, in \u001b[0;36mSeq2SeqBahdenau.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     13\u001b[0m inp \u001b[39m=\u001b[39m src[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, output_chunk_size):\n\u001b[0;32m---> 16\u001b[0m     output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(inp, hidden, encoder_outputs)\n\u001b[1;32m     17\u001b[0m     outputs[:,t,:] \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m     teacher_force \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom() \u001b[39m<\u001b[39m teacher_forcing_ratio\n","File \u001b[0;32m~/opt/anaconda3/envs/LearningBerkeley/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[171], line 69\u001b[0m, in \u001b[0;36mDecoderBahdanau.forward\u001b[0;34m(self, inp, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m weighted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mnis,nsk->nik\u001b[39m\u001b[39m'\u001b[39m, a, encoder_outputs) \u001b[39m# (N, 1, hidden_size * 2)')\u001b[39;00m\n\u001b[1;32m     67\u001b[0m inp \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m# (N, 1, input_size)\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m rnn_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((inp, weighted), dim \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m) \u001b[39m# (1, N, hidden_size * 3)\u001b[39;00m\n\u001b[1;32m     71\u001b[0m output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(rnn_input, hidden\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\n\u001b[1;32m     73\u001b[0m inp, output, weighted \u001b[39m=\u001b[39m inp\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m), output\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m), weighted\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n","\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 3"]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","enc = EncoderBahdanau(input_size=3, hidden_size=128)\n","dec = DecoderBahdanau(input_size=3, hidden_size=128)\n","model_bahdenau = Seq2SeqBahdenau(enc, dec)\n","wandb_logger = WandbLogger(project = 'SFH Load Forecasting', name = \"Bahdenau_Attention\")\n","\n","cbs = [EarlyStopping(monitor='val_loss')]\n","trainer = pl.Trainer(max_epochs=20, logger = wandb_logger, gpus=1 if torch.cuda.is_available() else 0, callbacks=cbs)\n","trainer.fit(model_bahdenau, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"]},{"cell_type":"markdown","metadata":{"id":"4aS9xB-MyRJb"},"source":["# Convolutional Seq2Seq\n","\n","https://arxiv.org/abs/1705.03122"]},{"cell_type":"markdown","metadata":{"id":"clVlGhAcWz2p"},"source":["### Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6vBiRNCGPoI"},"outputs":[],"source":["class EncoderConv(nn.Module):\n","  def __init__(self, input_size, emb_size, hid_size, n_layers, kernel_size, dropout, device, max_length= 100):\n","    super(EncoderConv, self).__init__()\n","\n","    assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\n","\n","    self.device = device\n","    # The scale variable is used by the authors to \"ensure that the variance\n","    # throughout the network does not change dramatically\".\n","    # The performance of the model seems to vary wildly\n","    # using different seeds if this is not used.\n","    self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device) # ~0.7\n","    self.tok_emb = nn.Linear(input_size,emb_size)\n","    self.pos_emb = nn.Embedding(max_length, emb_size)\n","    self.emb2hid = nn.Linear(emb_size, hid_size)\n","    self.hid2emb = nn.Linear(hid_size, emb_size)\n","    self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_size,\n","                                          out_channels = 2*hid_size,\n","                                          kernel_size = kernel_size,\n","                                          padding = (kernel_size -1) // 2\n","                                          )\n","                                for _ in range(n_layers)])\n","    self.dropout = nn.Dropout(dropout)\n","\n","\n","  def forward(self, src):\n","    batch_size = src.shape[0]\n","    src_len = src.shape[1]\n","\n","    #pos = [batch_size, src_len] (of the longest seq in the batch)\n","    pos = torch.arange(0,src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","\n","    tok_embedded = self.tok_emb(src)\n","    pos_embedded = self.pos_emb(pos)\n","\n","    #element-wise summing of embeddings\n","    #embedded = [batch_size, src_len, emb_size]\n","    embedded = self.dropout(tok_embedded + pos_embedded)\n","\n","    #conv_input = [batch_size, src_len, hidden_size]\n","    conv_input = self.emb2hid(embedded)\n","\n","    conv_input = torch.einsum('ijk->ikj', conv_input)\n","\n","    # conv likes dims = [batch_size, hidden_size, src_len]; n = batches, C_in = channels / hidden, L = length\n","    # https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n","    for i, conv in enumerate(self.convs):\n","\n","      conved = conv(self.dropout(conv_input))\n","\n","      conved = F.glu(conved, dim = 1) # 1 (k) dim is now [hidden_size * 2]\n","\n","      #residual\n","\n","      #print(self.scale)\n","      conved = (conved + conv_input) * self.scale # \n","\n","      conv_input = conved\n","\n","\n","    conved = torch.einsum('ikj->ijk', conved)\n","    conved = self.hid2emb(conved)\n","\n","    combined = (conved + embedded) * self.scale\n","\n","    return conved, combined\n","\n","\n","\n","\n","                                                    \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cc2eVF8qSQnY"},"outputs":[],"source":["enc_conv = EncoderConv(input_size=1, emb_size=1, hid_size=3, n_layers=2, kernel_size= 3, dropout = 0.5, device = device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669120724939,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"fCOP0M09SYmo","outputId":"a7743648-3e59-4b88-f420-a11eb163a08e"},"outputs":[{"data":{"text/plain":["torch.Size([8, 48, 1])"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["conved, combined = enc_conv(src)\n"]},{"cell_type":"markdown","metadata":{"id":"8XylnsnuWxcw"},"source":["### Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CloxXBmPSzAx"},"outputs":[],"source":["class DecoderConv(nn.Module):\n","\n","  def __init__(self,\n","               input_size,\n","               emb_size,\n","               hid_size,\n","               output_size,\n","               n_layers,\n","               kernel_size,\n","               dropout,\n","               trg_pad_idx,\n","               device, \n","               max_length=100):\n","    \n","    super(DecoderConv, self).__init__()\n","    \n","    self.device = device\n","    self.scale = torch.sqrt(torch.FloatTensor([0.5])).to(device) # ~0.7\n","    self.input_size = input_size\n","    self.hid_size = hid_size\n","    self.kernel_size = kernel_size\n","    self.trg_pad_idx = trg_pad_idx\n","\n","    self.dropout = nn.Dropout(dropout)\n","    self.tok_emb = nn.Linear(input_size, emb_size)\n","    self.pos_emb = nn.Embedding(max_length, emb_size)\n","    self.emb2hid = nn.Linear(emb_size, hid_size)\n","    self.hid2emb = nn.Linear(hid_size, emb_size)\n","    self.att_hid2emb = nn.Linear(hid_size, emb_size)\n","    self.att_emb2hid = nn.Linear(emb_size, hid_size)\n","    self.fc_out = nn.Linear(emb_size, output_size)\n","\n","\n","    self.convs = nn.ModuleList([nn.Conv1d(in_channels = hid_size,\n","                                          out_channels = 2*hid_size,\n","                                          kernel_size = kernel_size\n","                                          )\n","                                for _ in range(n_layers)])\n","\n","\n","\n","  def calc_att(self, embedded, conved, encoder_conved, encoder_combined):\n","\n","    \n","    #encoder_conved = [N, src, emb]\n","    #encoder_combined = [N, src, emb]\n","\n","    #conved; it comes out [N, hid_size, trg] from the conv1d layer \n","    conved_permuted = torch.einsum('nht->nth', conved)\n","    # -> [N, trg, hid]\n","\n","\n","    conved_emb = self.att_hid2emb(conved_permuted)\n","    # [N, trg, emb]\n","\n","    combined = (conved_emb + embedded) * self.scale\n","\n","    encoder_conved_perm = torch.einsum('nse->nes', encoder_conved)\n","\n","    energy = torch.einsum('nte,nes->nts', [combined, encoder_conved_perm])\n","\n","    attention = F.softmax(energy, dim = 2) #over the source dimension, because later the encoders are weighted\n","\n","    attended_encoding = torch.einsum('nts, nse->nte', attention, encoder_combined)\n","\n","    attended_encoding = self.att_emb2hid(attended_encoding)\n","    #[N, trg, hid]\n","\n","    attended_combined = (attended_encoding.permute(0,2,1) + conved) * self.scale\n","\n","\n","    return attention, attended_combined\n","\n","\n","\n","  def forward(self, trg, encoder_conved, encoder_combined):\n","\n","    batch_size = trg.shape[0]\n","    trg_len = trg.shape[1]\n","\n","    pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","\n","    tok_embedded = self.tok_emb(trg)\n","    pos_embedded = self.pos_emb(pos)\n","\n","    embedded = self.dropout(tok_embedded + pos_embedded)\n","\n","    conv_input = self.emb2hid(embedded)\n","\n","    conv_input = torch.einsum('nth->nht', conv_input)\n","\n","    for i, conv in enumerate(self.convs):\n","\n","      conv_input = self.dropout(conv_input)\n","\n","      # padding\n","      padding = torch.zeros(batch_size, self.hid_size, self.kernel_size -1).fill_(self.trg_pad_idx).to(self.device)\n","\n","      padded_conv_input = torch.cat((padding, conv_input), dim = 2)\n","      # [N, h, t+k-1]\n","\n","      conved = conv(padded_conv_input)\n","      # [N, 2*h, t]\n","\n","      conved = F.glu(conved, dim = 1) #glu halves the dimension, this is why we setup the convs that way\n","\n","      # [N, h , t]\n","\n","      attention, conved = self.calc_att(embedded, conved, encoder_conved, encoder_combined)\n","      # att: [N, t, s]\n","      #conved: [N, h, t]\n","\n","      conved = (conved + conv_input) * self.scale\n","\n","      conv_input = conved #pass to the next layer\n","\n","\n","    conved = self.hid2emb(conved.permute(0,2,1))\n","    # [N, t, e]\n","\n","    output = self.fc_out(self.dropout(conved))\n","    # [N, t, 1]\n","\n","    return output, attention\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1669122496281,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"Ey48-WHo5Sgo","outputId":"c3a1f31b-c01e-48ac-e061-3c1636e54c64"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  after removing the cwd from sys.path.\n"]}],"source":["\n","batch = iter(trainloader).next()\n","src, trg = batch\n","src = torch.tensor(src, dtype=torch.float32).to(device)\n","trg = torch.tensor(trg, dtype=torch.float32).to(device)\n","\n","\n","\n","dec = DecoderConv(\n","               input_size = 1,\n","               emb_size = 1,\n","               hid_size = 3,\n","               output_size = 1,\n","               n_layers= 2,\n","               kernel_size=3,\n","               dropout=0.1,\n","               trg_pad_idx= 1,\n","               device=device, \n","               max_length=100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKKOln8YWgFP"},"outputs":[],"source":["output, attn = dec(trg, conved, combined)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EDsmWD1EXVuU"},"outputs":[],"source":["class Seq2SeqConv(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        \n","    def forward(self, src, trg):\n","        \n","        #src = [batch size, src len]\n","        #trg = [batch size, trg len - 1] (<eos> token sliced off the end)\n","           \n","        #calculate z^u (encoder_conved) and (z^u + e) (encoder_combined)\n","        #encoder_conved is output from final encoder conv. block\n","        #encoder_combined is encoder_conved plus (elementwise) src embedding plus \n","        #  positional embeddings \n","        encoder_conved, encoder_combined = self.encoder(src)\n","            \n","        #encoder_conved = [batch size, src len, emb dim]\n","        #encoder_combined = [batch size, src len, emb dim]\n","        \n","        #calculate predictions of next words\n","        #output is a batch of predictions for each word in the trg sentence\n","        #attention a batch of attention scores across the src sentence for \n","        #  each word in the trg sentence\n","        output, attention = self.decoder(trg, encoder_conved, encoder_combined)\n","        \n","        #output = [batch size, trg len - 1, output dim]\n","        #attention = [batch size, trg len - 1, src len]\n","        \n","        return output, attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZNY32j7XdLUK"},"outputs":[],"source":["TRG_PAD_IDX = 1e-10\n","\n","\n","enc_conv = EncoderConv(input_size=1,\n","                       emb_size=1,\n","                       hid_size=3,\n","                       n_layers=2, \n","                       kernel_size= 3,\n","                       dropout = 0.5, \n","                       device = device)\n","\n","dec_conv = DecoderConv(\n","               input_size = 1,\n","               emb_size = 1,\n","               hid_size = 3,\n","               output_size = 1,\n","               n_layers= 2,\n","               kernel_size=3,\n","               dropout=0.1,\n","               trg_pad_idx= TRG_PAD_IDX,\n","               device=device, \n","               max_length=100)\n","\n","model_conv = Seq2SeqConv(enc_conv, dec_conv).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":877,"status":"ok","timestamp":1669122747518,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"-LYE_6kvdapt","outputId":"db0212b4-4c01-4869-b383-f53496643fd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 476 trainable parameters\n"]}],"source":["print(f'The model has {count_parameters(model_conv):,} trainable parameters')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FolC6hBcdsDC"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SE9Py5ecli_1"},"outputs":[],"source":["def generate_square_subsequent_mask(dim1: int, dim2: int):\n","    \"\"\"\n","    Generates an upper-triangular matrix of -inf, with zeros on diag.\n","    Modified from: \n","    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n","    Args:\n","        dim1: int, for both src and tgt masking, this must be target sequence\n","              length\n","        dim2: int, for src masking this must be encoder sequence length (i.e. \n","              the length of the input sequence to the model), \n","              and for tgt masking, this must be target sequence length \n","    Return:\n","        A Tensor of shape [dim1, dim2]\n","    \"\"\"\n","    return torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1669124758583,"user":{"displayName":"TimeCast AI","userId":"07364941519718465481"},"user_tz":-60},"id":"UfssyVUoljwQ","outputId":"b1339f86-7e33-4d88-d0f8-9b6f7a3858f4"},"outputs":[{"data":{"text/plain":["tensor([[0., -inf, -inf],\n","        [0., 0., -inf],\n","        [0., 0., 0.]])"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["generate_square_subsequent_mask(3,3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPdoNCdglpjw"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["cylh-CMwV9wB","9A_2CmwIA_Tf"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"gpu2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"2d017bf32283ba7f67b14df218f7d5e330099bbfa9a17c2165be9519c3d88acb"}}},"nbformat":4,"nbformat_minor":0}
>>>>>>> 67e7c02affc63a5c1937fb48196c8fdc0e28ddd8
